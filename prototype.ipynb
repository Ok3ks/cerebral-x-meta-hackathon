{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING GROQ With LLAMA INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.llms.groq import Groq\n",
    "import chromadb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROK_API_KEY = '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'\n",
    "LLAMA_HUB_API_KEY = 'llx-VbW7L7fNit8D5IdAKWGhDg1fzzc1SJUPiHQzqLRysQxRx5tQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model=\"llama-3.2-3b-preview\", api_key=GROK_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(\"Explain the importance of low latency LLMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low latency Large Language Models (LLMs) are crucial in various applications where real-time processing and response are essential. Here are some reasons why low latency LLMs are important:\n",
      "\n",
      "1. **Real-time Conversations**: In applications like chatbots, virtual assistants, and customer service platforms, low latency LLMs enable seamless and responsive conversations. Users expect immediate responses, and low latency ensures that the model can provide accurate and relevant information in a timely manner.\n",
      "2. **Gaming and Interactive Applications**: In games, interactive simulations, and other immersive experiences, low latency LLMs are vital for a smooth and engaging user experience. Fast response times allow for real-time decision-making, reducing lag and improving overall player satisfaction.\n",
      "3. **Financial Applications**: In high-stakes financial applications like trading platforms, stock analysis, and risk management, low latency LLMs are critical for making quick and informed decisions. Fast response times enable traders and analysts to react to market fluctuations and make timely decisions.\n",
      "4. **Healthcare and Medical Diagnosis**: In medical diagnosis and treatment, low latency LLMs can help analyze medical images, diagnose diseases, and provide personalized treatment recommendations. Fast response times enable healthcare professionals to make timely and accurate diagnoses, improving patient outcomes.\n",
      "5. **Autonomous Systems**: In autonomous vehicles, drones, and other self-driving systems, low latency LLMs are essential for real-time decision-making and navigation. Fast response times enable the system to react to changing environments and make accurate decisions.\n",
      "6. **Live Streaming and Video Analysis**: In live streaming and video analysis applications, low latency LLMs can help analyze video feeds, detect objects, and provide real-time insights. Fast response times enable users to react to events in real-time, improving overall user experience.\n",
      "7. **Predictive Maintenance**: In predictive maintenance applications, low latency LLMs can help analyze sensor data, detect anomalies, and predict equipment failures. Fast response times enable maintenance teams to take proactive measures, reducing downtime and improving overall efficiency.\n",
      "\n",
      "To achieve low latency, LLMs can employ various techniques, such as:\n",
      "\n",
      "1. **Model pruning**: Removing unnecessary weights and connections to reduce model size and computational requirements.\n",
      "2. **Quantization**: Representing model weights and activations using lower precision data types to reduce memory usage and computational requirements.\n",
      "3. **Knowledge distillation**: Transferring knowledge from a larger, more complex model to a smaller, more efficient model.\n",
      "4. **Efficient inference**: Using optimized inference algorithms and hardware accelerators to reduce computational requirements.\n",
      "5. **Distributed computing**: Distributing model computations across multiple machines or GPUs to reduce latency and improve scalability.\n",
      "\n",
      "By employing these techniques, developers can build low latency LLMs that provide fast and accurate responses, enabling a wide range of applications that require real-time processing and decision-making.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMA_HUB_API_KEY,  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
    "    # result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    num_workers=4,  # if multiple files passed, split in `num_workers` API calls\n",
    "    verbose=True,\n",
    "    language=\"en\",  # Optionally you can define a language, default=en\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cd3839c7-652b-401f-bf06-857eac152d23\n",
      "......................"
     ]
    }
   ],
   "source": [
    "\n",
    "# sync\n",
    "documents = parser.load_data(\"/Users/emmanuel/hackathon/docs/o-and-m-best-practice-guidelines-v-5-0-a07c44238b.pdf\")\n",
    "# documents = pdf_loader.load_data(\"/Users/emmanuel/hackathon/docs/o-and-m-best-practice-guidelines-v-5-0-a07c44238b.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "Started parsing the file under job_id 49a760b1-6e35-4f00-8195-ef9d01eadf73\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73/result/text \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/49a760b1-6e35-4f00-8195-ef9d01eadf73/result/text \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "Started parsing the file under job_id 7ac18740-543e-4a0c-b3c4-a4845dc3b5c4\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4/result/text \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7ac18740-543e-4a0c-b3c4-a4845dc3b5c4/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "second_document = parser.load_data(\"/Users/emmanuel/hackathon/docs/Guide_to_Solar_Optimization-Ark_Resources.pdf\")\n",
    "third_document = parser.load_data(\"/Users/emmanuel/hackathon/docs/Plant-documentation_ Information-advice-Menger.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "client_ = chromadb.PersistentClient(path=\"./embeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Any, Tuple\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def parse_document(file_path, parser):\n",
    "    \"\"\"Accepts both a file path and a list of file paths\"\"\"\n",
    "    documents = parser.load_data(file_path)\n",
    "    return documents\n",
    "\n",
    "def retrieve_similar(query:str, client: chromadb.Client, collection_name:str=\"constructionom\",  n_results=2): #Maybe add type hints later\n",
    "    \"\"\"Retrieves similar documents from a collection\"\"\"\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    results = collection.query( \n",
    "        query_texts=[query], # Chroma will embed this for you #can query embedding too\n",
    "        n_results=n_results # how many results to return\n",
    "    )\n",
    "    return results['documents']\n",
    "\n",
    "def prep_doc_for_upsert_document(documents:List[Any], embedding_model = SentenceTransformer()):\n",
    "    \"\"\"Upserts a document to the embedding store\"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    ids = []\n",
    "    text = []\n",
    "\n",
    "    for doc in documents:\n",
    "        embeddings.append(embedding_model.encode(doc.text))\n",
    "        ids.append(doc.doc_id)\n",
    "        text.append(doc.text)\n",
    "    return (ids,text)\n",
    "\n",
    "def upsert_embeddings(client:chromadb.Client, document:Tuple[List], embeddings, collection_name:str=\"constructionom\"):\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    collection.upsert(embeddings=document[2], documents=document[1], ids = document[0])\n",
    "    print(\"upsert done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentic Workflow with LLAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE EMBEDDINGS WITH SentenceTransformers , all-MiniLM-L6-v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.embedding = model.encode(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINETUNE EMBEDDING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SentenceSplitter()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guide_to_Solar_Optimization-Ark_Resources.pdf',\n",
       " 'Plant-documentation_ Information-advice-Menger.pdf',\n",
       " 'o-and-m-best-practice-guidelines-v-5-0-a07c44238b.pdf']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = load_corpus([\"/Users/emmanuel/hackathon/docs/\" + i for i in  os.listdir('docs')])\n",
    "val_nodes = load_corpus([\"/Users/emmanuel/hackathon/test_docs/\" + i  for i in  os.listdir('test_docs')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "train_dataset = generate_qa_embedding_pairs(\n",
    "    llm=llm,\n",
    "    nodes=train_nodes,\n",
    "    output_path=\"train_dataset.json\",\n",
    ")\n",
    "val_dataset = generate_qa_embedding_pairs(\n",
    "    llm=llm,\n",
    "    nodes=val_nodes,\n",
    "    output_path=\"val_dataset.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmanuel/.virtualenvs/hackathon-cmtz/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n",
      "PyTorch version 2.5.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en\n"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"BAAI/bge-small-en\",\n",
    "    model_output_path=\"test_model\",\n",
    "    val_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 29/58 [00:37<00:35,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset after epoch 1.0:\n",
      "Information Retrieval Evaluation of the model on the  dataset after epoch 1.0:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 32\n",
      "Queries: 32\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 16\n",
      "\n",
      "Corpus: 16\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 43.75%\n",
      "Accuracy@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 56.25%\n",
      "Accuracy@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 65.62%\n",
      "Accuracy@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 78.12%\n",
      "Accuracy@10: 78.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 43.75%\n",
      "Precision@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 18.75%\n",
      "Precision@3: 18.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 13.12%\n",
      "Precision@5: 13.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 7.81%\n",
      "Precision@10: 7.81%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 43.75%\n",
      "Recall@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 56.25%\n",
      "Recall@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 65.62%\n",
      "Recall@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 78.12%\n",
      "Recall@10: 78.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5326\n",
      "MRR@10: 0.5326\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.5911\n",
      "NDCG@10: 0.5911\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5495\n",
      "MAP@100: 0.5495\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to test_model\n",
      "Save model to test_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 50/58 [01:04<00:10,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset:\n",
      "Information Retrieval Evaluation of the model on the  dataset:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 32\n",
      "Queries: 32\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 16\n",
      "\n",
      "Corpus: 16\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 43.75%\n",
      "Accuracy@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 56.25%\n",
      "Accuracy@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 65.62%\n",
      "Accuracy@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 81.25%\n",
      "Accuracy@10: 81.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 43.75%\n",
      "Precision@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 18.75%\n",
      "Precision@3: 18.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 13.12%\n",
      "Precision@5: 13.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.13%\n",
      "Precision@10: 8.13%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 43.75%\n",
      "Recall@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 56.25%\n",
      "Recall@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 65.62%\n",
      "Recall@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 81.25%\n",
      "Recall@10: 81.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5372\n",
      "MRR@10: 0.5372\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.6015\n",
      "NDCG@10: 0.6015\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5513\n",
      "MAP@100: 0.5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 50/58 [01:05<00:10,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_cosine_accuracy@1': 0.4375, 'eval_cosine_accuracy@3': 0.5625, 'eval_cosine_accuracy@5': 0.65625, 'eval_cosine_accuracy@10': 0.8125, 'eval_cosine_precision@1': 0.4375, 'eval_cosine_precision@3': 0.1875, 'eval_cosine_precision@5': 0.13125, 'eval_cosine_precision@10': 0.08125000000000002, 'eval_cosine_recall@1': 0.4375, 'eval_cosine_recall@3': 0.5625, 'eval_cosine_recall@5': 0.65625, 'eval_cosine_recall@10': 0.8125, 'eval_cosine_ndcg@10': 0.6015018928953357, 'eval_cosine_mrr@10': 0.5371899801587301, 'eval_cosine_map@100': 0.5512559922716173, 'eval_runtime': 0.5108, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 1.72}\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to test_model\n",
      "Save model to test_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [01:15<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the  dataset after epoch 2.0:\n",
      "Information Retrieval Evaluation of the model on the  dataset after epoch 2.0:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 32\n",
      "Queries: 32\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 16\n",
      "\n",
      "Corpus: 16\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 43.75%\n",
      "Accuracy@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 56.25%\n",
      "Accuracy@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 65.62%\n",
      "Accuracy@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 81.25%\n",
      "Accuracy@10: 81.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 43.75%\n",
      "Precision@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 18.75%\n",
      "Precision@3: 18.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 13.12%\n",
      "Precision@5: 13.12%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.13%\n",
      "Precision@10: 8.13%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 43.75%\n",
      "Recall@1: 43.75%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 56.25%\n",
      "Recall@3: 56.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 65.62%\n",
      "Recall@5: 65.62%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 81.25%\n",
      "Recall@10: 81.25%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.5382\n",
      "MRR@10: 0.5382\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.6025\n",
      "NDCG@10: 0.6025\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.5520\n",
      "MAP@100: 0.5520\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to test_model\n",
      "Save model to test_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [01:15<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 75.8673, 'train_samples_per_second': 7.592, 'train_steps_per_second': 0.764, 'train_loss': 1.3479036791571255, 'epoch': 2.0}\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: test_model\n",
      "Load pretrained SentenceTransformer: test_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "finetune_engine.finetune()\n",
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.57it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_emb = []\n",
    "for doc in third_document:\n",
    "    xy = await embed_model.aget_text_embedding(doc.text[0])\n",
    "    temp_emb.append(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE EMBEDDINGS WITH CHROMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsert done\n"
     ]
    }
   ],
   "source": [
    "upsert_embeddings(client=client_, embeddings=temp_emb, document=prep_doc_for_upsert_document(third_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = await embed_model.aget_text_embedding(\"Tell me about solar panels installation in europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PersistentClient(path: str = \"./chroma\",\n",
    "#                      settings: Optional[Settings] = None,\n",
    "#                      tenant: str = DEFAULT_TENANT,\n",
    "#                      database: str = DEFAULT_DATABASE) -> ClientAPI\n",
    "\n",
    "#prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Context: [['SolarPower Europe would like to thank the members of its Lifecycle\\nQuality Workstream that contributed to this report including:\\n                                                                  WIND\\n\\n\\n\\n\\n\\n\\n                                                                   ENPHASE\\n      everoze                                                       Fraunhofer\\n                                                                               CSP\\n                                            3  Solar\\n                                                                  Qe n e r G Y\\n                             Sonnedix\\n                                                  ENERGY\\n                                                        WISE\\n     Sponsor members of SolarPower Europe:\\n             BayWa re:\\n             re.think energy\\nOperation & Maintenance Best Practice Guidelines / Version 5.0\\n\\n\\n\\n  amarenco                               APREN\\nBsW                                       CEA\\nBundesverband     T E C H N O L O G I E cast4allS\\nSolarwintschaft\\n                      ELETTRIGITA\\n                   Tesearch\\n\\n                        Energia\\n\\n\\n\\n\\n\\n\\n\\n\\n                                HUAwEC', 'SolarPower Europe - Leading the Energy Transition\\nRond-point Robert Schuman 3, 1040 Brussels, Belgium\\nT +32 2 709 55 20 / F +32 2 725 32 50\\ninfo@solarpowereurope.org / www.solarpowereurope.org\\n\\n                                                      ISBN NUMBER 9789464444247']]\n",
      "I can provide you with detailed instructions on how to extract information about solar panels installation in Europe from the given context.\n",
      "\n",
      "**Step 1: Understand the context**\n",
      "\n",
      "The given context is a list of organizations and companies that have contributed to a report by SolarPower Europe. The report is related to the lifecycle quality of solar panels, and the context includes a list of sponsors and contributors.\n",
      "\n",
      "**Step 2: Identify relevant information**\n",
      "\n",
      "To answer the question about solar panels installation in Europe, we need to look for information related to solar panels, installation, and Europe. However, the given context does not provide explicit information about solar panels installation in Europe.\n",
      "\n",
      "**Step 3: Analyze the content**\n",
      "\n",
      "Upon analyzing the content, we can see that the report is related to the lifecycle quality of solar panels, and it includes a list of contributors from various organizations. However, there is no mention of solar panels installation in Europe.\n",
      "\n",
      "**Step 4: Conclusion**\n",
      "\n",
      "Based on the analysis, it appears that the given context does not provide sufficient information about solar panels installation in Europe. Therefore, I must conclude that I do not know the answer to this question based on the provided context.\n",
      "\n",
      "If you would like to provide more context or clarify the question, I'll be happy to try and assist you further.\n"
     ]
    }
   ],
   "source": [
    "question= \"Tell me about solar panels installation in europe\"\n",
    "context = retrieve_similar(client=client_, query=question)\n",
    "\n",
    "context_answer = llm.complete(f\"\"\"Using only {context} as context, \n",
    "                              can you please provide detailed instruction this question? {question}. \n",
    "                              If the context {context}  does not correspond with the question {question}, please say you do not know\"\"\")\n",
    "print(f\"Context: {context}\")\n",
    "print(context_answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reflection Agent which asseses the prompt in relation to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can provide you with detailed instructions on solar panel installation in Europe. Here's a comprehensive guide:\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "Solar panel installation is a popular renewable energy source in Europe, with many countries setting ambitious targets to reduce greenhouse gas emissions and increase the use of renewable energy. In this guide, we'll cover the key steps involved in installing solar panels in Europe.\n",
      "\n",
      "**Pre-Installation Requirements**\n",
      "\n",
      "Before installing solar panels, you'll need to:\n",
      "\n",
      "1. **Check local regulations**: Familiarize yourself with local building codes, zoning laws, and regulations regarding solar panel installation. Some countries have specific requirements for solar panel installations, such as minimum roof size or orientation.\n",
      "2. **Assess your energy needs**: Determine your energy consumption and assess whether solar panels can meet your energy needs. Consider factors like your energy usage patterns, roof size, and shading.\n",
      "3. **Choose a suitable location**: Select a location with sufficient sunlight, ideally facing south or southwest. Avoid areas with shading from trees, buildings, or other obstructions.\n",
      "4. **Obtain necessary permits**: Secure the required permits and approvals from local authorities before commencing installation.\n",
      "\n",
      "**Solar Panel Installation Steps**\n",
      "\n",
      "1. **Assess your roof**: Inspect your roof for any damage, debris, or obstructions that may affect solar panel installation.\n",
      "2. **Measure your roof**: Measure your roof's size, orientation, and shading to determine the optimal solar panel layout.\n",
      "3. **Choose the right solar panels**: Select solar panels that meet your energy needs and are compatible with your roof type and shading conditions.\n",
      "4. **Install mounting hardware**: Install the mounting hardware, such as racking systems, to secure the solar panels to your roof.\n",
      "5. **Install solar panels**: Mount the solar panels to the roof, ensuring proper alignment and spacing.\n",
      "6. **Connect solar panels**: Connect the solar panels to a solar inverter, which converts DC power to AC power.\n",
      "7. **Install electrical connections**: Connect the solar panel system to your electrical panel and ensure proper electrical connections.\n",
      "8. **Test the system**: Test the solar panel system to ensure it's functioning correctly and producing electricity.\n",
      "\n",
      "**European-Specific Considerations**\n",
      "\n",
      "1. **EU's Renewable Energy Directive**: The EU's Renewable Energy Directive sets a target of at least 32% of final energy consumption coming from renewable energy sources by 2030.\n",
      "2. **Net Metering**: Many European countries offer net metering, which allows households and businesses to sell excess energy back to the grid.\n",
      "3. **Grid Connection**: Ensure that your solar panel system is connected to the grid and meets local grid connection requirements.\n",
      "4. **Energy Storage**: Consider installing energy storage systems, such as batteries, to store excess energy for later use.\n",
      "\n",
      "**Popular Solar Panel Installation Countries in Europe**\n",
      "\n",
      "1. **Germany**: Germany is a leader in solar panel installation, with over 2 million solar panels installed in 2020.\n",
      "2. **France**: France has set ambitious targets to increase solar panel installations, with a goal of 10 GW of solar power by 2025.\n",
      "3. **UK**: The UK has seen significant growth in solar panel installations, with over 1 GW of solar power installed in 2020.\n",
      "4. **Italy**: Italy has a large solar panel market, with over 1 GW of solar power installed in 2020.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Solar panel installation is a viable and cost-effective way to reduce your energy bills and carbon footprint in Europe. By following these steps and considering European-specific regulations and incentives, you can ensure a successful solar panel installation.\n"
     ]
    }
   ],
   "source": [
    "non_context_answer = llm.complete(f\"\"\"Using your knowledge base. \n",
    "                              can you please provide detailed instruction this question? {question}. \n",
    "                              If it isn't present in your knowledge base, please say you do not know\"\"\")\n",
    "print(non_context_answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection. peek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-cmtz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
